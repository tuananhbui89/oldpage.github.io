<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="theme" content="hugo-academic">
  <meta name="generator" content="Hugo 0.32" />
  <meta name="author" content="Tuan-Anh Bui">

  
  
  
  
    
      
    
  
  <meta name="description" content="Given a set of images of a space, such as an office, which is captured by several cameras, how can infer a scene of that space when viewed from a particular point of view? I noticed that despite there is plenty different approaches attack to this problem; we might see there is still not complete solution as we might hope. We might use some advanced methods of Structure-from-Motion (SfM) to reconstruct the 3D model from the set of images then infer the scene we desire from 3D coordinate corresponding with 3D model. However, this approach cannot work on a low-depth object and requires to calibrate all camera, and the most important is that 3D model does not convey the appearance information. There are several other methods such as wrapping and combining images from nearby viewpoint. However, those methods require two images taken from slightly different viewpoints. In this project, I would like to propose a new end-to-end learning based generative model, that can generate a scene from a pose (position and orientation) directly. That model based on Generative Adversarial Networks to learn a hidden transformation between two domains: pose domain and scene domain without explicitly understanding the distribution of two domains. To my best knowledge, this project will be the first approach in the field of view synthesis with an arbitrary pose">

  
  <link rel="alternate" hreflang="en-us" href="https://tuananhbui89.github.io/publication/sencenet/">

  


  

  
  
  <meta name="theme-color" content="#0095eb">
  
  
  
  
    
  
  
    
    
      
        <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
      
    
  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha512-6MXa8B6uaO18Hid6blRMetEIoPqHf7Ux1tnyIQdpt9qI5OACx7C+O3IVTr98vwGnlcg0LOLa02i9Y1HpVhlfiw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.1/css/academicons.min.css" integrity="sha512-NThgw3XKQ1absAahW6to7Ey42uycrVvfNfyjqcFNgCmOCQ5AR4AO0SiXrN+8ZtYeappp56lk1WtvjVmEa+VR6A==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha512-SfTiTlX6kk+qitfevl/7LibUOeJWlt9rbyDn92a1DqWOw9vWG2MFoays0sgObmWazO5BQPiFucnnEAjpAB+/Sw==" crossorigin="anonymous">
  
  
  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700%7cRoboto:400,400italic,700%7cRoboto&#43;Mono">
  
  <link rel="stylesheet" href="/styles.css">
  

  

  
  <link rel="alternate" href="https://tuananhbui89.github.io/index.xml" type="application/rss+xml" title="Tuan-Anh Bui">
  <link rel="feed" href="https://tuananhbui89.github.io/index.xml" type="application/rss+xml" title="Tuan-Anh Bui">
  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://tuananhbui89.github.io/publication/sencenet/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="og:site_name" content="Tuan-Anh Bui">
  <meta property="og:url" content="https://tuananhbui89.github.io/publication/sencenet/">
  <meta property="og:title" content="SceneNet: A generative model for generating scene from 6-DOF camera pose | Tuan-Anh Bui">
  <meta property="og:description" content="Given a set of images of a space, such as an office, which is captured by several cameras, how can infer a scene of that space when viewed from a particular point of view? I noticed that despite there is plenty different approaches attack to this problem; we might see there is still not complete solution as we might hope. We might use some advanced methods of Structure-from-Motion (SfM) to reconstruct the 3D model from the set of images then infer the scene we desire from 3D coordinate corresponding with 3D model. However, this approach cannot work on a low-depth object and requires to calibrate all camera, and the most important is that 3D model does not convey the appearance information. There are several other methods such as wrapping and combining images from nearby viewpoint. However, those methods require two images taken from slightly different viewpoints. In this project, I would like to propose a new end-to-end learning based generative model, that can generate a scene from a pose (position and orientation) directly. That model based on Generative Adversarial Networks to learn a hidden transformation between two domains: pose domain and scene domain without explicitly understanding the distribution of two domains. To my best knowledge, this project will be the first approach in the field of view synthesis with an arbitrary pose">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2018-01-11T00:00:00&#43;00:00">
  
  <meta property="article:modified_time" content="2018-01-11T00:00:00&#43;00:00">
  

  

  <title>SceneNet: A generative model for generating scene from 6-DOF camera pose | Tuan-Anh Bui</title>

</head>
<body id="top" data-spy="scroll" data-target="#toc" data-offset="71" >

<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container">

    
    <div class="navbar-header">
      
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
              data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
      <a class="navbar-brand" href="/">Tuan-Anh Bui</a>
    </div>

    
    <div class="collapse navbar-collapse">

      
      
      <ul class="nav navbar-nav navbar-right">
        

        

        
          
        

        <li class="nav-item">
          <a href="/#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        

        
          
        

        <li class="nav-item">
          <a href="/#publications_selected">
            
            <span>Publications</span>
            
          </a>
        </li>

        
        

        

        
          
        

        <li class="nav-item">
          <a href="/#posts">
            
            <span>Posts</span>
            
          </a>
        </li>

        
        

        

        
          
        

        <li class="nav-item">
          <a href="/#projects">
            
            <span>Projects</span>
            
          </a>
        </li>

        
        

        

        
          
        

        <li class="nav-item">
          <a href="/#contact">
            
            <span>Contact</span>
            
          </a>
        </li>

        
        
      

      
      </ul>

    </div>
  </div>
</nav>

<div class="pub" itemscope itemtype="http://schema.org/CreativeWork">

  


  <div class="container pub-title">
    <h1 itemprop="name">SceneNet: A generative model for generating scene from 6-DOF camera pose</h1>
    <span class="pub-authors" itemprop="author">
      
      Tuan-Anh Bui
      
    </span>
    <span class="pull-right">
      
<div class="share-box" aria-hidden="true">
  <ul class="share">
    <li>
      <a class="twitter"
         href="https://twitter.com/intent/tweet?text=SceneNet%3a%20A%20generative%20model%20for%20generating%20scene%20from%206-DOF%20camera%20pose&amp;url=https%3a%2f%2ftuananhbui89.github.io%2fpublication%2fsencenet%2f"
         target="_blank" rel="noopener">
        <i class="fa fa-twitter"></i>
      </a>
    </li>
    <li>
      <a class="facebook"
         href="https://www.facebook.com/sharer.php?u=https%3a%2f%2ftuananhbui89.github.io%2fpublication%2fsencenet%2f"
         target="_blank" rel="noopener">
        <i class="fa fa-facebook"></i>
      </a>
    </li>
    <li>
      <a class="linkedin"
         href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2ftuananhbui89.github.io%2fpublication%2fsencenet%2f&amp;title=SceneNet%3a%20A%20generative%20model%20for%20generating%20scene%20from%206-DOF%20camera%20pose"
         target="_blank" rel="noopener">
        <i class="fa fa-linkedin"></i>
      </a>
    </li>
    <li>
      <a class="weibo"
         href="http://service.weibo.com/share/share.php?url=https%3a%2f%2ftuananhbui89.github.io%2fpublication%2fsencenet%2f&amp;title=SceneNet%3a%20A%20generative%20model%20for%20generating%20scene%20from%206-DOF%20camera%20pose"
         target="_blank" rel="noopener">
        <i class="fa fa-weibo"></i>
      </a>
    </li>
    <li>
      <a class="email"
         href="mailto:?subject=SceneNet%3a%20A%20generative%20model%20for%20generating%20scene%20from%206-DOF%20camera%20pose&amp;body=https%3a%2f%2ftuananhbui89.github.io%2fpublication%2fsencenet%2f">
        <i class="fa fa-envelope"></i>
      </a>
    </li>
  </ul>
</div>


    </span>
  </div>

  <div class="article-container">

    

    
    <h3>Abstract</h3>
    <p class="pub-abstract" itemprop="text">Given a set of images of a space, such as an office, which is captured by several cameras, how can infer a scene of that space when viewed from a particular point of view? I noticed that despite there is plenty different approaches attack to this problem; we might see there is still not complete solution as we might hope. We might use some advanced methods of Structure-from-Motion (SfM) to reconstruct the 3D model from the set of images then infer the scene we desire from 3D coordinate corresponding with 3D model. However, this approach cannot work on a low-depth object and requires to calibrate all camera, and the most important is that 3D model does not convey the appearance information. There are several other methods such as wrapping and combining images from nearby viewpoint. However, those methods require two images taken from slightly different viewpoints. In this project, I would like to propose a new end-to-end learning based generative model, that can generate a scene from a pose (position and orientation) directly. That model based on Generative Adversarial Networks to learn a hidden transformation between two domains: pose domain and scene domain without explicitly understanding the distribution of two domains. To my best knowledge, this project will be the first approach in the field of view synthesis with an arbitrary pose</p>
    

    
    <div class="row">
      <div class="col-sm-1"></div>
      <div class="col-sm-10">
        <div class="row">
          <div class="col-xs-12 col-sm-3 pub-row-heading">Type</div>
          <div class="col-xs-12 col-sm-9">
            
            <a href="/publication/#3">
              Manuscript
            </a>
            
          </div>
        </div>
      </div>
      <div class="col-sm-1"></div>
    </div>
    <div class="visible-xs space-below"></div>
    

    
    <div class="row">
      <div class="col-sm-1"></div>
      <div class="col-sm-10">
        <div class="row">
          <div class="col-xs-12 col-sm-3 pub-row-heading">Publication</div>
          <div class="col-xs-12 col-sm-9">Proposal</div>
        </div>
      </div>
      <div class="col-sm-1"></div>
    </div>
    <div class="visible-xs space-below"></div>
    

    <div class="row">
      <div class="col-sm-1"></div>
      <div class="col-sm-10">
        <div class="row">
          <div class="col-xs-12 col-sm-3 pub-row-heading">Date</div>
          <div class="col-xs-12 col-sm-9" itemprop="datePublished">
            January, 2018
          </div>
        </div>
      </div>
      <div class="col-sm-1"></div>
    </div>
    <div class="visible-xs space-below"></div>

    <div class="row" style="padding-top: 10px">
      <div class="col-sm-1"></div>
      <div class="col-sm-10">
        <div class="row">
          <div class="col-xs-12 col-sm-3 pub-row-heading" style="line-height:34px;">Links</div>
          <div class="col-xs-12 col-sm-9">

            




<a class="btn btn-primary btn-outline" href="https://tuananhbui89.github.io/files/SenceNet.pdf" target="_blank" rel="noopener">
  PDF
</a>








<a class="btn btn-primary btn-outline" href="/project/invpose/">
  Project
</a>









          </div>
        </div>
      </div>
      <div class="col-sm-1"></div>
    </div>
    <div class="visible-xs space-below"></div>

    <div class="space-below"></div>

    <div class="article-style"></div>

    


  </div>
</div>

<div class="container">
  <nav>
  <ul class="pager">
    

    
    <li class="next"><a href="https://tuananhbui89.github.io/publication/aaai18/">On-device Scalable Image-based Localization <span
      aria-hidden="true">&rarr;</span></a></li>
    
  </ul>
</nav>

</div>

<footer class="site-footer">
  <div class="container">
    <p class="powered-by">

      &copy; 2018 &middot; 

      Powered by the
      <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
      <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

      <span class="pull-right" aria-hidden="true">
        <a href="#" id="back_to_top">
          <span class="button_icon">
            <i class="fa fa-chevron-up fa-2x"></i>
          </span>
        </a>
      </span>

    </p>
  </div>
</footer>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close btn-large" data-dismiss="modal">&times;</button>
        <h4 class="modal-title">Cite</h4>
      </div>
      <div>
        <pre><code class="modal-body tex"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-primary btn-outline js-copy-cite" href="#" target="_blank">
          <i class="fa fa-copy"></i> Copy
        </a>
        <a class="btn btn-primary btn-outline js-download-cite" href="#" target="_blank">
          <i class="fa fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    

    

    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js" integrity="sha512-3P8rXCuGJdNZOnUx/03c1jOTnMn3rP63nBip5gOP2qmUh5YAdVAvFZ1E+QLZZbC1rtMrQb+mah3AfYW11RUrWA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha512-iztkobsvnjKfAtTNdHkGVjAYTrrtlC7mGp/54c40wowO7LhURYl3gVzzcEqGl/qKXQltJ2HwMrdLcNUdo+N/RQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
    
    
    <script src="/js/hugo-academic.js"></script>
    

    
    
      
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
      

      

      

      <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
    </script>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML" integrity="sha512-tOav5w1OjvsSJzePRtt2uQPFwBoHt1VZcUq8l8nm5284LEKE9FSJBQryzMBzHxY5P0zRdNqEcpLIRVYFNgu1jw==" crossorigin="anonymous"></script>
    
    

  </body>
</html>

